{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vApjYF-P7UIjP9aEHnEBfLohi6JSCkhT",
      "authorship_tag": "ABX9TyM4C331k8Ah3JqEI52hmElH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aradeyal/machine_learning/blob/main/%D7%A8%D7%A9%D7%AA_%D7%A2%D7%9E%D7%95%D7%A7%D7%94_%D7%AA%D7%A8%D7%92%D7%99%D7%9C_%D7%9E%D7%A2%D7%A9%D7%99%E2%80%8E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8NpN4J8_VI",
        "outputId": "cf12ddd4-ce93-4202-e1dd-145dfc5a0c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Reading from: /content/winequality-red.csv\n",
            "\n",
            "=== Regression ===\n",
            "RMSE: 0.667 | MAE: 0.517\n",
            "\n",
            "=== Classification ===\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[ 0  0  1  1  0  0]\n",
            " [ 0  0  9  2  0  0]\n",
            " [ 0  1 93 41  1  0]\n",
            " [ 0  2 22 94 10  0]\n",
            " [ 0  0  0 22 18  0]\n",
            " [ 0  0  0  2  1  0]]\n",
            "Accuracy: 0.641\n"
          ]
        }
      ],
      "source": [
        "import os, sys, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, accuracy_score\n",
        "\n",
        "# ------------------------------- 1) CSV loader -------------------------------\n",
        "CANDIDATE_PATHS = [\n",
        "    r\"C:\\Users\\arade\\Downloads\\winequality-red.csv\",  # your Windows path\n",
        "    \"/content/winequality-red.csv\",                   # Colab (manual upload)\n",
        "    \"winequality-red.csv\",                            # current directory\n",
        "]\n",
        "\n",
        "def try_read_all(path: str):\n",
        "    \"\"\"Try reading CSV from 'path' with common separators; return DataFrame or None.\"\"\"\n",
        "    # a) semicolon\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep=\";\")\n",
        "        if df.shape[1] > 1:\n",
        "            return df\n",
        "    except Exception:\n",
        "        pass\n",
        "    # b) comma\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep=\",\")\n",
        "        if df.shape[1] > 1:\n",
        "            return df\n",
        "    except Exception:\n",
        "        pass\n",
        "    # c) pandas sniffer\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep=None, engine=\"python\")\n",
        "        if df.shape[1] > 1:\n",
        "            return df\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def load_wine_df():\n",
        "    # A) Use an existing candidate path if found\n",
        "    for p in CANDIDATE_PATHS:\n",
        "        if os.path.exists(p):\n",
        "            print(f\"📄 Reading from: {p}\")\n",
        "            df = try_read_all(p)\n",
        "            if df is not None:\n",
        "                return df\n",
        "    # B) In Colab: ask for manual upload (no Drive needed)\n",
        "    if 'google.colab' in sys.modules:\n",
        "        from google.colab import files\n",
        "        print(\"⚠️ File not found. Please upload 'winequality-red.csv' (no Drive).\")\n",
        "        uploaded = files.upload()\n",
        "        fname = next(iter(uploaded))\n",
        "        print(f\"📄 Reading from uploaded file: {fname}\")\n",
        "        df = try_read_all(fname)\n",
        "        if df is not None:\n",
        "            return df\n",
        "    # C) Last resort: download from UCI\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "    print(f\"⬇️ Downloading from UCI: {url}\")\n",
        "    local_path = tf.keras.utils.get_file(\"winequality-red.csv\", origin=url)\n",
        "    df = try_read_all(local_path)\n",
        "    if df is None:\n",
        "        raise FileNotFoundError(\"Could not load CSV with any method.\")\n",
        "    return df\n",
        "\n",
        "df = load_wine_df()\n",
        "\n",
        "# ------------------------------ 2) Preprocessing -----------------------------\n",
        "# Clean column names\n",
        "df.columns = (df.columns\n",
        "                .str.strip()\n",
        "                .str.replace(r\"\\s+\", \"_\", regex=True)\n",
        "                .str.lower())\n",
        "\n",
        "# Convert object columns to numeric where possible (also handle comma decimals)\n",
        "for c in df.columns:\n",
        "    if df[c].dtype == \"object\":\n",
        "        df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \".\"), errors=\"coerce\")\n",
        "\n",
        "# Drop rows with NaN (rare in this dataset)\n",
        "if df.isna().any().any():\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Detect target column\n",
        "target_col = \"quality\" if \"quality\" in df.columns else None\n",
        "if target_col is None:\n",
        "    for c in df.columns:\n",
        "        if re.fullmatch(r\"\\s*quality\\s*\", c, flags=re.IGNORECASE):\n",
        "            target_col = c\n",
        "            break\n",
        "if target_col is None:\n",
        "    target_col = df.columns[-1]\n",
        "    print(f\"ℹ️ 'quality' not found, using last column as target: '{target_col}'\")\n",
        "\n",
        "# Build X/y with numeric target\n",
        "y_series = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
        "mask = y_series.notna()\n",
        "X_all = df.drop(columns=[target_col]).loc[mask].astype(\"float32\").values\n",
        "y_all = y_series.loc[mask].astype(\"int64\").values\n",
        "\n",
        "# ------------------------- 3) Split first, then scale ------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "batch = 32\n",
        "steps = max(1, len(X_train) // batch)\n",
        "\n",
        "# ------------------------------ 4) Regression --------------------------------\n",
        "y_train_reg = y_train.astype(\"float32\")\n",
        "y_test_reg  = y_test.astype(\"float32\")\n",
        "\n",
        "train_reg = tf.data.Dataset.from_tensor_slices((X_train, y_train_reg)).shuffle(1000).repeat().batch(batch)\n",
        "test_reg  = tf.data.Dataset.from_tensor_slices((X_test,  y_test_reg)).batch(batch)\n",
        "\n",
        "reg_model = tf.keras.Sequential([\n",
        "    tf.keras.Input((X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"linear\"),\n",
        "])\n",
        "reg_model.compile(\n",
        "    optimizer=\"adam\", loss=\"mse\",\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\"]\n",
        ")\n",
        "reg_model.fit(train_reg, validation_data=test_reg, steps_per_epoch=steps, epochs=40, verbose=0)\n",
        "\n",
        "y_pred_reg = reg_model.predict(X_test, verbose=0).ravel()\n",
        "\n",
        "# sklearn-version-safe RMSE\n",
        "try:\n",
        "    rmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)\n",
        "except TypeError:\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))  # for older sklearn\n",
        "mae  = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(\"\\n=== Regression ===\")\n",
        "print(f\"RMSE: {rmse:.3f} | MAE: {mae:.3f}\")\n",
        "\n",
        "# --------------------------- 5) Classification --------------------------------\n",
        "# Map actual quality labels to contiguous indices: e.g., {3,4,5,6,7,8} -> {0..5}\n",
        "classes_sorted = np.sort(np.unique(y_all))\n",
        "label_to_idx = {label: i for i, label in enumerate(classes_sorted)}\n",
        "idx_to_label = np.array(classes_sorted)\n",
        "\n",
        "y_train_idx = np.array([label_to_idx[v] for v in y_train], dtype=\"int64\")\n",
        "y_test_idx  = np.array([label_to_idx[v] for v in y_test],  dtype=\"int64\")\n",
        "num_classes = len(classes_sorted)\n",
        "\n",
        "train_cls = tf.data.Dataset.from_tensor_slices((X_train, y_train_idx)).shuffle(1000).repeat().batch(batch)\n",
        "test_cls  = tf.data.Dataset.from_tensor_slices((X_test,  y_test_idx)).batch(batch)\n",
        "\n",
        "cls_model = tf.keras.Sequential([\n",
        "    tf.keras.Input((X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "])\n",
        "cls_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "cls_model.fit(train_cls, validation_data=test_cls, steps_per_epoch=steps, epochs=40, verbose=0)\n",
        "\n",
        "proba = cls_model.predict(X_test, verbose=0)\n",
        "y_pred_idx = proba.argmax(axis=1)\n",
        "y_pred_labels = idx_to_label[y_pred_idx]  # back to original quality values\n",
        "\n",
        "print(\"\\n=== Classification ===\")\n",
        "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "print(confusion_matrix(y_test, y_pred_labels, labels=classes_sorted))\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test_idx, y_pred_idx), 3))\n"
      ]
    }
  ]
}